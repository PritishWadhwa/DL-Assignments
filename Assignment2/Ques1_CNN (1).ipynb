{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from collections import Counter\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset after normalizing, converting to tensor and converting each to a standard size\n",
    "dataset = datasets.ImageFolder('./data/', transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)), transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({0: 11032, 1: 11014})\n",
      "test Counter({0: 1401, 1: 1355})\n",
      "val Counter({1: 1410, 0: 1346})\n",
      "22046 2756 2756\n"
     ]
    }
   ],
   "source": [
    "# Converting the train, val, test split\n",
    "trainSize = int(0.8*len(dataset))\n",
    "valSize = (len(dataset) - trainSize)//2\n",
    "testSize = len(dataset) - trainSize - valSize\n",
    "\n",
    "trainData, valData, testData = random_split(dataset, [trainSize, valSize, testSize])\n",
    "\n",
    "trainClasses = [dataset.targets[i] for i in (trainData.indices)]\n",
    "print('train', Counter(trainClasses))\n",
    "testClasses = [dataset.targets[i] for i in (testData.indices)]\n",
    "print('test', Counter(testClasses))\n",
    "valClasses = [dataset.targets[i] for i in (valData.indices)]\n",
    "print('val', Counter(valClasses))\n",
    "\n",
    "print(len(trainData), len(valData), len(testData))\n",
    "\n",
    "# entering the data into dataloaders\n",
    "train_loader = DataLoader(trainData, 128, shuffle = True)\n",
    "test_loader = DataLoader(testData, 128, shuffle = True)\n",
    "valid_loader = DataLoader(valData, 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    '''\n",
    "    Function to display the image\n",
    "    '''\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "classes=['infected','uninfected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mann/.conda/envs/base3.6/lib/python3.6/site-packages/ipykernel_launcher.py:18: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infected = 0\n",
    "uninfected = 0\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "for i in range(len(dataiter)):\n",
    "    if infected == 5 and uninfected == 5:\n",
    "        break\n",
    "    if labels[i] == 0:\n",
    "        if infected == 5:\n",
    "            continue\n",
    "        infected += 1\n",
    "    else:\n",
    "        if uninfected == 5:\n",
    "            continue\n",
    "        uninfected += 1\n",
    "    ax = fig.add_subplot(2, 10/2, i+1, xticks=[], yticks=[])\n",
    "    imshow(images[i])\n",
    "    ax.set_title(classes[labels[i]])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# # plot the images in the batch, along with the corresponding label\n",
    "# fig = plt.figure(figsize=(25, 4))\n",
    "# # display 20 images\n",
    "# for idx in np.arange(20):\n",
    "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "#     imshow(images[idx])\n",
    "#     ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,16,kernel_size=9, padding=1)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.conv2=nn.Conv2d(16,32,kernel_size=6, padding=1)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.conv3=nn.Conv2d(32,64,kernel_size=3, padding=1)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "#         self.conv4=nn.Conv2d(64,128,kernel_size=(4,4))\n",
    "#         self.pool4=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.fc1=nn.Linear(1*1*64,32)\n",
    "#         self.fc2=nn.Linear(500,100)\n",
    "        self.fc3=nn.Linear(32,1)\n",
    "        self.dropout=nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.pool1(F.relu(self.conv1(x)))\n",
    "#         x=self.dropout(x)\n",
    "        x=self.pool2(F.relu(self.conv2(x)))\n",
    "#         x=self.dropout(x)\n",
    "        x=self.pool3(F.relu(self.conv3(x)))\n",
    "#         x=self.dropout(x)\n",
    "        x=x.reshape( -1,1*1*64)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "#         x=self.dropout(x)\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=self.dropout(x)\n",
    "        x=F.sigmoid(self.fc3(x))\n",
    "#         x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:41<00:00,  4.12it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.616655 \tValidation Loss: 0.608533\n",
      "Validation loss decreased (inf --> 0.608533).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.08it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.494265 \tValidation Loss: 0.413486\n",
      "Validation loss decreased (0.608533 --> 0.413486).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.344126 \tValidation Loss: 0.332836\n",
      "Validation loss decreased (0.413486 --> 0.332836).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 3\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "#         data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "#         data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 85.01%\n",
      "Test Loss: 0.336026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "#     data = data.to(device)\n",
    "#     target = target.to(device)\n",
    "#     data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "#     _, pred = torch.max(output, 1)    \n",
    "#     acc = (output.reshape(-1).detach().numpy().round() == target).mean()\n",
    "    acc = sum(output.reshape(-1).detach().round() == target)\n",
    "\n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    nCorrect += acc\n",
    "#     for i in range(len(pred)):\n",
    "#         if pred[i] == target[i]:\n",
    "#             nCorrect += 1\n",
    "#     correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "#     correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "#     for i in range(len(target)):\n",
    "#         label = target.data[i]\n",
    "#         class_correct[label] += correct[i].item()\n",
    "#         class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "# for i in range(2):\n",
    "#     if class_total[i] > 0:\n",
    "#         print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "#             classes[i], 100 * class_correct[i] / class_total[i],\n",
    "#             np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "#     else:\n",
    "#         print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "# print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "#     100. * np.sum(class_correct) / np.sum(class_total),\n",
    "#     np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 85.01%\n",
      "Test Loss: 0.336026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "#     data = data.to(device)\n",
    "#     target = target.to(device)\n",
    "#     data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "#     _, pred = torch.max(output, 1)    \n",
    "#     acc = (output.reshape(-1).detach().numpy().round() == target).mean()\n",
    "    acc = sum(output.reshape(-1).detach().round() == target)\n",
    "\n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    nCorrect += acc\n",
    "#     for i in range(len(pred)):\n",
    "#         if pred[i] == target[i]:\n",
    "#             nCorrect += 1\n",
    "#     correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "#     correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "#     for i in range(len(target)):\n",
    "#         label = target.data[i]\n",
    "#         class_correct[label] += correct[i].item()\n",
    "#         class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "# for i in range(2):\n",
    "#     if class_total[i] > 0:\n",
    "#         print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "#             classes[i], 100 * class_correct[i] / class_total[i],\n",
    "#             np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "#     else:\n",
    "#         print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "# print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "#     100. * np.sum(class_correct) / np.sum(class_total),\n",
    "#     np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9886e-01],\n",
       "        [9.9938e-01],\n",
       "        [9.9112e-01],\n",
       "        [7.2965e-09],\n",
       "        [3.6931e-08],\n",
       "        [2.5272e-11],\n",
       "        [1.3663e-18],\n",
       "        [4.8758e-05],\n",
       "        [5.4083e-06],\n",
       "        [5.6858e-06],\n",
       "        [2.3578e-06],\n",
       "        [9.9803e-01],\n",
       "        [4.8378e-06],\n",
       "        [9.9748e-01],\n",
       "        [4.5690e-07],\n",
       "        [9.9539e-01],\n",
       "        [1.1384e-08],\n",
       "        [9.3385e-02],\n",
       "        [5.0279e-01],\n",
       "        [8.4658e-01],\n",
       "        [3.5975e-01],\n",
       "        [5.2042e-04],\n",
       "        [9.7258e-01],\n",
       "        [3.6088e-03],\n",
       "        [9.9937e-01],\n",
       "        [2.6754e-16],\n",
       "        [1.7479e-12],\n",
       "        [5.4760e-01],\n",
       "        [7.4815e-01],\n",
       "        [3.5020e-24]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5655, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "    data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            nCorrect += 1\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "#     for i in range(len(target)):\n",
    "#         label = target.data[i]\n",
    "#         class_correct[label] += correct[i].item()\n",
    "#         class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 74.60%\n",
      "Test Loss: 0.519764\n",
      "\n",
      "Test Accuracy of infected: 61% (853/1395)\n",
      "Test Accuracy of uninfected: 88% (1203/1361)\n",
      "\n",
      "Test Accuracy (Overall): 74% (2056/2756)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(valid_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            nCorrect += 1\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, weightInit='he'):\n",
    "        super(Net, self).__init__()\n",
    "        self.weightType = weightInit\n",
    "        self.blockA=nn.Conv2d(3,16,kernel_size=9, padding=1)\n",
    "        self.initializeWeights(self.blockA)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.blockB=nn.Conv2d(16,32,kernel_size=6, padding=1)\n",
    "        self.initializeWeights(self.blockB)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.blockC=nn.Conv2d(32,64,kernel_size=3, padding=1)\n",
    "        self.initializeWeights(self.blockC)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.fc1=nn.Linear(1*1*64,32)\n",
    "        self.initializeWeights(self.fc1)\n",
    "        self.fc2=nn.Linear(32,2)\n",
    "        self.initializeWeights(self.fc2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.pool1(F.relu(self.blockA(x)))\n",
    "        x=self.pool2(F.relu(self.blockB(x)))\n",
    "        x=self.pool3(F.relu(self.blockC(x)))\n",
    "        x=x.reshape( -1,1*1*64)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def initializeWeights(self, w):\n",
    "        if self.weightType == 'zero':\n",
    "            nn.init.zeros_(w.weight)\n",
    "        elif self.weightType == 'random':\n",
    "            nn.init.normal_(w.weight)\n",
    "        else:\n",
    "            nn.init.kaiming_normal_(w.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blockA): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockB): Conv2d(16, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockC): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net('zero').to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.26it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.693035 \tValidation Loss: 0.691320\n",
      "Validation loss decreased (inf --> 0.691320).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.26it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.680159 \tValidation Loss: 0.667477\n",
      "Validation loss decreased (0.691320 --> 0.667477).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.26it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.648948 \tValidation Loss: 0.636726\n",
      "Validation loss decreased (0.667477 --> 0.636726).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.23it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.617013 \tValidation Loss: 0.611209\n",
      "Validation loss decreased (0.636726 --> 0.611209).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.593453 \tValidation Loss: 0.603700\n",
      "Validation loss decreased (0.611209 --> 0.603700).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_weight_zero.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_weight_zero.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 74.09%\n",
      "Test Loss: 0.592043\n",
      "\n",
      "Test Accuracy of infected: 67% (928/1375)\n",
      "Test Accuracy of uninfected: 80% (1114/1381)\n",
      "\n",
      "Test Accuracy (Overall): 74% (2042/2756)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            nCorrect += 1\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blockA): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockB): Conv2d(16, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockC): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net('random').to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.26it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 9300.056273 \tValidation Loss: 4391.250725\n",
      "Validation loss decreased (inf --> 4391.250725).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.25it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 3635.946136 \tValidation Loss: 3115.334410\n",
      "Validation loss decreased (4391.250725 --> 3115.334410).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.26it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 2797.942251 \tValidation Loss: 2609.015476\n",
      "Validation loss decreased (3115.334410 --> 2609.015476).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.25it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 2364.879982 \tValidation Loss: 2301.092736\n",
      "Validation loss decreased (2609.015476 --> 2301.092736).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 2051.863524 \tValidation Loss: 2034.970966\n",
      "Validation loss decreased (2301.092736 --> 2034.970966).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_weight_random.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_weight_random.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 62.99%\n",
      "Test Loss: 2100.967022\n",
      "\n",
      "Test Accuracy of infected: 58% (799/1375)\n",
      "Test Accuracy of uninfected: 67% (937/1381)\n",
      "\n",
      "Test Accuracy (Overall): 62% (1736/2756)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            nCorrect += 1\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blockA): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockB): Conv2d(16, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockC): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net('he').to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.28it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.548032 \tValidation Loss: 0.475209\n",
      "Validation loss decreased (inf --> 0.475209).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.24it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.435565 \tValidation Loss: 0.417525\n",
      "Validation loss decreased (0.475209 --> 0.417525).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.27it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.379032 \tValidation Loss: 0.363930\n",
      "Validation loss decreased (0.417525 --> 0.363930).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.23it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.336817 \tValidation Loss: 0.324920\n",
      "Validation loss decreased (0.363930 --> 0.324920).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:40<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.284262 \tValidation Loss: 0.321741\n",
      "Validation loss decreased (0.324920 --> 0.321741).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_weight_he.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_weight_he.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 86.28%\n",
      "Test Loss: 0.313750\n",
      "\n",
      "Test Accuracy of infected: 93% (1288/1375)\n",
      "Test Accuracy of uninfected: 78% (1090/1381)\n",
      "\n",
      "Test Accuracy (Overall): 86% (2378/2756)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            nCorrect += 1\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, weightInit='he'):\n",
    "        super(Net, self).__init__()\n",
    "        self.weightType = weightInit\n",
    "        self.blockA=nn.Conv2d(3,16,kernel_size=9, padding=1)\n",
    "        self.initializeWeights(self.blockA)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.blockB=nn.Conv2d(16,32,kernel_size=6, padding=1)\n",
    "        self.initializeWeights(self.blockB)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.blockC=nn.Conv2d(32,64,kernel_size=3, padding=1)\n",
    "        self.initializeWeights(self.blockC)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.fc1=nn.Linear(1*1*64,32)\n",
    "        self.initializeWeights(self.fc1)\n",
    "        self.fc2=nn.Linear(32,2)\n",
    "        self.initializeWeights(self.fc2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.pool1(F.relu(self.blockA(x)))\n",
    "        x=self.pool2(F.relu(self.blockB(x)))\n",
    "        x=self.pool3(F.relu(self.blockC(x)))\n",
    "        x=x.reshape( -1,1*1*64)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def initializeWeights(self, w):\n",
    "        if self.weightType == 'zero':\n",
    "            nn.init.zeros_(w.weight)\n",
    "        elif self.weightType == 'random':\n",
    "            nn.init.normal_(w.weight)\n",
    "        else:\n",
    "            nn.init.kaiming_normal_(w.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, weightInit='he'):\n",
    "        super(Net, self).__init__()\n",
    "        self.weightType = weightInit\n",
    "        self.blockA=nn.Conv2d(3,16,kernel_size=9, padding=1)\n",
    "        self.initializeWeights(self.blockA)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.blockB=nn.Conv2d(16,32,kernel_size=6, padding=1)\n",
    "        self.initializeWeights(self.blockB)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.blockC=nn.Conv2d(32,64,kernel_size=3, padding=1)\n",
    "        self.initializeWeights(self.blockC)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=(3,3),stride=2)\n",
    "        self.fc1=nn.Linear(1*1*64,32)\n",
    "        self.initializeWeights(self.fc1)\n",
    "        self.fc2=nn.Linear(32,1)\n",
    "        self.initializeWeights(self.fc2)\n",
    "        self.dropout=nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.pool1(F.relu(self.blockA(x)))\n",
    "        x=self.pool2(F.relu(self.blockB(x)))\n",
    "        x=self.pool3(F.relu(self.blockC(x)))\n",
    "        x=x.reshape( -1,1*1*64)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def initializeWeights(self, w):\n",
    "        if self.weightType == 'zero':\n",
    "            nn.init.zeros_(w.weight)\n",
    "        elif self.weightType == 'random':\n",
    "            nn.init.normal_(w.weight)\n",
    "        else:\n",
    "            nn.init.kaiming_normal_(w.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blockA): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockB): Conv2d(16, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockC): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.07it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.581820 \tValidation Loss: 0.518495\n",
      "Validation loss decreased (inf --> 0.518495).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.12it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.462264 \tValidation Loss: 0.417355\n",
      "Validation loss decreased (0.518495 --> 0.417355).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.09it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.403889 \tValidation Loss: 0.375760\n",
      "Validation loss decreased (0.417355 --> 0.375760).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.08it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.348860 \tValidation Loss: 0.320413\n",
      "Validation loss decreased (0.375760 --> 0.320413).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.312027 \tValidation Loss: 0.299002\n",
      "Validation loss decreased (0.320413 --> 0.299002).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "#         data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "#         data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 87.59%\n",
      "Test Loss: 0.297205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "#     data = data.to(device)\n",
    "#     target = target.to(device)\n",
    "#     data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "#     _, pred = torch.max(output, 1)    \n",
    "#     acc = (output.reshape(-1).detach().numpy().round() == target).mean()\n",
    "    acc = sum(output.reshape(-1).detach().round() == target)\n",
    "\n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    nCorrect += acc\n",
    "#     for i in range(len(pred)):\n",
    "#         if pred[i] == target[i]:\n",
    "#             nCorrect += 1\n",
    "#     correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "#     correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "#     for i in range(len(target)):\n",
    "#         label = target.data[i]\n",
    "#         class_correct[label] += correct[i].item()\n",
    "#         class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "# for i in range(2):\n",
    "#     if class_total[i] > 0:\n",
    "#         print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "#             classes[i], 100 * class_correct[i] / class_total[i],\n",
    "#             np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "#     else:\n",
    "#         print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "# print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "#     100. * np.sum(class_correct) / np.sum(class_total),\n",
    "#     np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blockA): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockB): Conv2d(16, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (blockC): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.06it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.854335 \tValidation Loss: 2.359871\n",
      "Validation loss decreased (inf --> 2.359871).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.04it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 2.031510 \tValidation Loss: 1.765519\n",
      "Validation loss decreased (2.359871 --> 1.765519).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:43<00:00,  4.02it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 1.553603 \tValidation Loss: 1.379570\n",
      "Validation loss decreased (1.765519 --> 1.379570).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:42<00:00,  4.05it/s]\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 1.252325 \tValidation Loss: 1.144587\n",
      "Validation loss decreased (1.379570 --> 1.144587).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:43<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 1.082577 \tValidation Loss: 0.990792\n",
      "Validation loss decreased (1.144587 --> 0.990792).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 5\n",
    "l1_lambda = 1e-3\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "#         data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        l1_norm = sum(abs(p).sum() for p in model.parameters())\n",
    "        loss = loss + l1_lambda * l1_norm\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "#         if torch.cuda.is_available():\n",
    "#         data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "        l1_norm = sum(abs(p).sum() for p in model.parameters())\n",
    "        loss = loss + l1_lambda * l1_norm\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84.91%\n",
      "Test Loss: 0.992048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "nCorrect = 0\n",
    "nSamples = 0\n",
    "for data, target in tqdm(test_loader):\n",
    "#     data = data.to(device)\n",
    "#     target = target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         data, target = data.cuda(), target.cuda()\n",
    "#     data = data.to(device)\n",
    "#     target = target.to(device)\n",
    "#     data, target = data.to(device), target.reshape((-1, 1)).to(torch.float32).to(device)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target.reshape(-1, 1).to(torch.float32))\n",
    "    l1_norm = sum(abs(p).sum() for p in model.parameters())\n",
    "    loss = loss + l1_lambda * l1_norm\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "#     _, pred = torch.max(output, 1)    \n",
    "#     acc = (output.reshape(-1).detach().numpy().round() == target).mean()\n",
    "    acc = sum(output.reshape(-1).detach().round() == target)\n",
    "\n",
    "    # compare predictions to true label\n",
    "#     target = target.to(torch.long)\n",
    "    nSamples += target.shape[0]\n",
    "    nCorrect += acc\n",
    "#     for i in range(len(pred)):\n",
    "#         if pred[i] == target[i]:\n",
    "#             nCorrect += 1\n",
    "#     correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "#     correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#     calculate test accuracy for each object class\n",
    "    \n",
    "    \n",
    "#     for i in range(len(target)):\n",
    "#         label = target.data[i]\n",
    "#         class_correct[label] += correct[i].item()\n",
    "#         class_total[label] += 1\n",
    "    \n",
    "acc = 100.0 * nCorrect / nSamples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "    \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "# for i in range(2):\n",
    "#     if class_total[i] > 0:\n",
    "#         print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "#             classes[i], 100 * class_correct[i] / class_total[i],\n",
    "#             np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "#     else:\n",
    "#         print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "# print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "#     100. * np.sum(class_correct) / np.sum(class_total),\n",
    "#     np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
