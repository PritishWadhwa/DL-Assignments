{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_aISAgNly79",
        "outputId": "18f71a41-8764-4854-dcfc-3e4e97092519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "uchrlIN4l5oW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d7P-CR6HeuwD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading csv file\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/DL_DialogDataset/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/DL_DialogDataset/test.csv\")\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KfDqCJ-el__U",
        "outputId": "a9d7224d-c44a-48f1-f587-26622e34d7c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              utterance  act\n",
              "0     Say , Jim , how about going for a few beers af...    3\n",
              "1      You know that is tempting but is really not g...    4\n",
              "2        What do you mean ? It will help us to relax .     2\n",
              "3      Do you really think so ? I don't . It will ju...    2\n",
              "4      I guess you are right.But what shall we do ? ...    2\n",
              "...                                                 ...  ...\n",
              "5085               Tom and Helen got married at last .     1\n",
              "5086   How did you know that ? I heart Tom ’ s fathe...    2\n",
              "5087           I was invited to attend their wedding .     1\n",
              "5088   It ’ s great . Although his father didn ’ t a...    1\n",
              "5089                              How moving love is .     1\n",
              "\n",
              "[5090 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81cc7310-b5ac-4bd5-8246-72d1148fe9a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>act</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Say , Jim , how about going for a few beers af...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You know that is tempting but is really not g...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you mean ? It will help us to relax .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do you really think so ? I don't . It will ju...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I guess you are right.But what shall we do ? ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5085</th>\n",
              "      <td>Tom and Helen got married at last .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5086</th>\n",
              "      <td>How did you know that ? I heart Tom ’ s fathe...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087</th>\n",
              "      <td>I was invited to attend their wedding .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5088</th>\n",
              "      <td>It ’ s great . Although his father didn ’ t a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5089</th>\n",
              "      <td>How moving love is .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5090 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81cc7310-b5ac-4bd5-8246-72d1148fe9a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81cc7310-b5ac-4bd5-8246-72d1148fe9a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81cc7310-b5ac-4bd5-8246-72d1148fe9a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = train.utterance\n",
        "ytrain = train.act\n",
        "Xtest = test.utterance\n",
        "ytest = test.act\n",
        "  "
      ],
      "metadata": {
        "id": "o7N2pmXPnJ8U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "uD21uaO7nkOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpXMAc77fpj2",
        "outputId": "ad27da7c-9988-417b-da9b-57dcaa01cda0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.68-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 57.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.1.68 pyahocorasick-1.4.4 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lowerCase(df):\n",
        "  df= df.apply(lambda x: x.lower())\n",
        "  return df\n",
        "\n",
        "Xtrain = lowerCase(Xtrain)\n",
        "Xtest = lowerCase(Xtest)"
      ],
      "metadata": {
        "id": "GGCVogsQerYl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "def contractionExpand(text):\n",
        "  return contractions.fix(text)\n",
        "\n",
        "Xtrain = Xtrain.apply(lambda x: contractionExpand(x))"
      ],
      "metadata": {
        "id": "pG6AeBDrhyPp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest = Xtest.apply(lambda x: contractionExpand(x))"
      ],
      "metadata": {
        "id": "_9LIHIIlapzF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenize(text):\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  return tokens\n",
        "\n",
        "Xtrain = Xtrain.apply(lambda x: tokenize(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0WGZyfkfczn",
        "outputId": "21785f40-33e4-4ec3-a196-65e0bfc1e554"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest = Xtest.apply(lambda x: tokenize(x))"
      ],
      "metadata": {
        "id": "pDq0UUymatwm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCMzbVVEgt2i",
        "outputId": "57106a13-b355-4c6e-b6f5-e6b10a56a726"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [say, ,, jim, ,, how, about, going, for, a, fe...\n",
              "1       [you, know, that, is, tempting, but, is, reall...\n",
              "2       [what, do, you, mean, ?, it, will, help, us, t...\n",
              "3       [do, you, really, think, so, ?, i, do, not, .,...\n",
              "4       [i, guess, you, are, right.but, what, shall, w...\n",
              "                              ...                        \n",
              "5085         [tom, and, helen, got, married, at, last, .]\n",
              "5086    [how, did, you, know, that, ?, i, heart, tom, ...\n",
              "5087     [i, was, invited, to, attend, their, wedding, .]\n",
              "5088    [it, ’, s, great, ., although, his, father, di...\n",
              "5089                           [how, moving, love, is, .]\n",
              "Name: utterance, Length: 5090, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNqqj6OTaxN_",
        "outputId": "5128f9ae-d879-40b2-ef4f-fdd5fc26c4a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [i, am, better, now, ., want, to, play, again, ?]\n",
              "1      [i, will, let, you, break, the, balls, this, t...\n",
              "2      [let, us, get, all, the, balls, out, of, the, ...\n",
              "3      [ok, ., how, much, do, you, want, to, bet, on,...\n",
              "4      [you, are, crazy, ., gambling, is, against, my...\n",
              "                             ...                        \n",
              "717    [yeah, ,, i, got, to, eat, as, much, pizza, as...\n",
              "718                       [did, you, like, the, play, ?]\n",
              "719    [not, really, ., it, is, a, dull, one, ,, and,...\n",
              "720    [you, are, absolutely, right, ., the, acting, ...\n",
              "721    [to, be, fair, ,, though, ,, both, the, costum...\n",
              "Name: utterance, Length: 722, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = len(max(Xtrain, key=len))"
      ],
      "metadata": {
        "id": "KjUl_Gvggu-A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len_test = len(max(Xtest, key=len))"
      ],
      "metadata": {
        "id": "cM1t8X_obA-j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence Embedding for each utterance: Using Glove and then pooling"
      ],
      "metadata": {
        "id": "HB9TUZgKCXfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!ls -lat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwKpOnrTsH-R",
        "outputId": "65d5df11-d129-48bb-ae89-6c704f577d72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-28 18:45:59--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-03-28 18:45:59--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-03-28 18:45:59--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.13MB/s    in 2m 40s  \n",
            "\n",
            "2022-03-28 18:48:39 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "total 3039148\n",
            "drwxr-xr-x 1 root root       4096 Mar 28 18:48 .\n",
            "drwx------ 6 root root       4096 Mar 28 18:45 drive\n",
            "drwxr-xr-x 1 root root       4096 Mar 28 18:44 ..\n",
            "drwxr-xr-x 1 root root       4096 Mar 23 14:22 sample_data\n",
            "drwxr-xr-x 4 root root       4096 Mar 23 14:21 .config\n",
            "-rw-r--r-- 1 root root  862182613 Oct 25  2015 glove.6B.zip\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-rw-r-- 1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab,embeddings = [],[]\n",
        "with open('glove.6B.50d.txt','rt') as fi:\n",
        "    full_content = fi.read().strip().split('\\n')\n",
        "for i in range(len(full_content)):\n",
        "    i_word = full_content[i].split(' ')[0]\n",
        "    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
        "    vocab.append(i_word)\n",
        "    embeddings.append(i_embeddings)"
      ],
      "metadata": {
        "id": "T5ToUVnqsK9a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_npa = np.array(vocab)\n",
        "embs_npa = np.array(embeddings)"
      ],
      "metadata": {
        "id": "CQyBjN4ysLq0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insert '<pad>' and '<unk>' tokens at start of vocab_npa.\n",
        "vocab_npa = np.insert(vocab_npa, 0, '<pad>')\n",
        "vocab_npa = np.insert(vocab_npa, 1, '<unk>')\n",
        "print(vocab_npa[:10])\n",
        "\n",
        "pad_emb_npa = np.zeros((1,embs_npa.shape[1]))   #embedding for '<pad>' token.\n",
        "unk_emb_npa = np.mean(embs_npa,axis=0,keepdims=True)    #embedding for '<unk>' token.\n",
        "\n",
        "#insert embeddings for pad and unk tokens at top of embs_npa.\n",
        "embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))\n",
        "print(embs_npa.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-ge-vSssOaw",
        "outputId": "edb8c8b4-d41a-45c8-c988-bbdae29149d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>' '<unk>' 'the' ',' '.' 'of' 'to' 'and' 'in' 'a']\n",
            "(400002, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_embedding_layer = torch.nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float())\n",
        "\n",
        "assert my_embedding_layer.weight.shape == embs_npa.shape\n",
        "print(my_embedding_layer.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o01qckQNsRMA",
        "outputId": "87748814-6be6-4eff-80ab-5056632ef233"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([400002, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_text_to_id(df,vocab,unk_token,pad_to_len,pad_token):\n",
        "  word2idx = {term:idx for idx,term in enumerate(vocab)}\n",
        "  idx2word = {idx:word for word,idx in word2idx.items()}\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    deficit = pad_to_len - len(df[i])\n",
        "    df[i].extend([pad_token]*deficit)\n",
        "    for j in range(len(df[i])):\n",
        "      if df[i][j] not in word2idx:\n",
        "        df[i][j] = word2idx[unk_token]\n",
        "      else:\n",
        "        df[i][j] = word2idx[df[i][j]]\n",
        "  return df\n",
        "\n",
        "\n",
        "Xtrain_id = convert_text_to_id(Xtrain,vocab_npa,'<unk>',max_seq_len,'<pad>')\n"
      ],
      "metadata": {
        "id": "DJ9vlKsCkNBV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest_id = convert_text_to_id(Xtest,vocab_npa,'<unk>',max_seq_len_test,'<pad>')"
      ],
      "metadata": {
        "id": "_MiUNXvUbKM8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Xtrain_id[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHFGSJrCBlU1",
        "outputId": "ff759241-6193-4eb0-afef-18a79d806ae4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Va15sar7Yvn",
        "outputId": "c5dab9e9-08a3-4b6f-af57-67766b709c37"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [205, 3, 2017, 3, 199, 61, 224, 12, 9, 308, 13...\n",
              "1       [83, 348, 14, 16, 21655, 36, 16, 590, 38, 221,...\n",
              "2       [104, 90, 83, 1704, 190, 22, 45, 277, 97, 6, 1...\n",
              "3       [90, 83, 590, 271, 102, 190, 43, 90, 38, 4, 22...\n",
              "4       [43, 5022, 83, 34, 1, 104, 5286, 55, 90, 190, ...\n",
              "                              ...                        \n",
              "5085    [1616, 7, 7216, 407, 1169, 24, 78, 4, 0, 0, 0,...\n",
              "5086    [199, 121, 83, 348, 14, 190, 43, 1060, 1616, 3...\n",
              "5087    [43, 17, 2862, 6, 2057, 46, 4320, 4, 0, 0, 0, ...\n",
              "5088    [22, 3073, 1536, 355, 4, 378, 28, 631, 73332, ...\n",
              "5089    [199, 1235, 837, 16, 4, 0, 0, 0, 0, 0, 0, 0, 0...\n",
              "Name: utterance, Length: 5090, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "Xtrain_id = np.array(Xtrain_id)\n",
        "Xtrain_id= np.vstack(Xtrain_id).astype('int')\n",
        "ytrain = np.array(ytrain)\n",
        "ytrain = ytrain - 1\n",
        "train_data = TensorDataset(torch.from_numpy(Xtrain_id), torch.from_numpy(ytrain))\n"
      ],
      "metadata": {
        "id": "PCZ2TMFg1Phy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest_id = np.array(Xtest_id)\n",
        "Xtest_id= np.vstack(Xtest_id).astype('int')\n",
        "ytest = np.array(ytest)\n",
        "ytest = ytest - 1\n",
        "test_data = TensorDataset(torch.from_numpy(Xtest_id), torch.from_numpy(ytest))"
      ],
      "metadata": {
        "id": "XiiLGbdDbSTK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQIQdRNZWv0n",
        "outputId": "e3d98456-c2e0-4fd4-e62f-aa6c096a27b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataLoader = DataLoader(train_data,batch_size=32)"
      ],
      "metadata": {
        "id": "iUWRDrPXkNiF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDataLoader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "STY2ccMrbgYe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClass(nn.Module):\n",
        "    def __init__(self,embs_nps,hidden_size,num_layers,drop_prob):\n",
        "        super().__init__()\n",
        "        self.vocab_size = embs_npa.shape[0]\n",
        "        self.embedding_dim = embs_npa.shape[1]\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float(),freeze=True)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,self.embedding_dim))\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim,hidden_size=self.hidden_size,num_layers=self.num_layers,batch_first=True,bidirectional=False)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.linear = nn.Linear(hidden_size, 4)\n",
        "        # self.softmax = nn.Softmax()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "      embed_out = self.embedding(x)\n",
        "      # print(\"emb\",embed_out.shape)\n",
        "      sentence_embed_out = self.pool(embed_out)\n",
        "      # print(\"Senemb\",sentence_embed_out.shape)\n",
        "      hnot = torch.zeros(self.num_layers,x.size(0),self.hidden_size).to(device)\n",
        "      cnot = torch.zeros(self.num_layers,x.size(0),self.hidden_size).to(device)\n",
        "      out,_ = self.lstm(sentence_embed_out,(hnot,cnot))\n",
        "      out = out[:,-1,:]\n",
        "      # print(\"lstm\",out.shape)\n",
        "      # out = self.dropout(out)\n",
        "      out = self.linear(out)\n",
        "      # print(\"lin\",out.shape)\n",
        "      # out = self.softmax(out)\n",
        "      return out"
      ],
      "metadata": {
        "id": "pkeZNTPw1SCR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTMClass(embs_npa,256,1,0.2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(lstm.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "jBR-EjRh6HVc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "totalSteps = len(trainDataLoader)\n",
        "numEpochs = 2\n",
        "X = 2  # X previous utterances for t th utterance\n",
        "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in tqdm(enumerate(trainDataLoader)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        # print(\"l\",labels.shape)\n",
        "        # print(labels)\n",
        "        labels = labels.reshape((-1,)).to(device)\n",
        "        # print(\"l\",labels.shape)\n",
        "        # print(labels)\n",
        "        \n",
        "        outputs = lstm(inputs)\n",
        "          \n",
        "        # outputs = torch.squeeze(outputs)\n",
        "        # outputs = outputs.reshape((-1, 1))\n",
        "        # print(outputs.shape)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    \n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch {epoch + 1} / {numEpochs}, Step {i+1} / {totalSteps}, Loss: {loss.item():.4f}')\n",
        "            # print(outputs)\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrgQuNUO6IG2",
        "outputId": "496af02f-2c67-47ae-9c3c-efdad2d12a4d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "27it [00:00, 91.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 2, Step 10 / 160, Loss: 1.2260\n",
            "Epoch 1 / 2, Step 20 / 160, Loss: 0.6718\n",
            "Epoch 1 / 2, Step 30 / 160, Loss: 0.7292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "54it [00:00, 114.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 2, Step 40 / 160, Loss: 1.1773\n",
            "Epoch 1 / 2, Step 50 / 160, Loss: 1.2134\n",
            "Epoch 1 / 2, Step 60 / 160, Loss: 1.0491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "95it [00:00, 125.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 2, Step 70 / 160, Loss: 0.9515\n",
            "Epoch 1 / 2, Step 80 / 160, Loss: 0.8669\n",
            "Epoch 1 / 2, Step 90 / 160, Loss: 1.0670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "122it [00:01, 127.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 2, Step 100 / 160, Loss: 0.8975\n",
            "Epoch 1 / 2, Step 110 / 160, Loss: 0.8577\n",
            "Epoch 1 / 2, Step 120 / 160, Loss: 0.8935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "148it [00:01, 120.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 2, Step 130 / 160, Loss: 0.7036\n",
            "Epoch 1 / 2, Step 140 / 160, Loss: 0.6445\n",
            "Epoch 1 / 2, Step 150 / 160, Loss: 0.9972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r160it [00:01, 113.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 2, Step 160 / 160, Loss: 0.3381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [00:00, 126.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 10 / 160, Loss: 0.9576\n",
            "Epoch 2 / 2, Step 20 / 160, Loss: 0.5656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [00:00, 126.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 30 / 160, Loss: 0.6433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "53it [00:00, 129.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 40 / 160, Loss: 1.1423\n",
            "Epoch 2 / 2, Step 50 / 160, Loss: 1.0493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r66it [00:00, 126.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 60 / 160, Loss: 0.8986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r80it [00:00, 128.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 70 / 160, Loss: 0.6818\n",
            "Epoch 2 / 2, Step 80 / 160, Loss: 0.8373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r94it [00:00, 127.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 90 / 160, Loss: 0.8553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r107it [00:00, 124.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 100 / 160, Loss: 0.7660\n",
            "Epoch 2 / 2, Step 110 / 160, Loss: 0.7828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r120it [00:00, 124.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 120 / 160, Loss: 0.7428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r133it [00:01, 122.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 130 / 160, Loss: 0.6102\n",
            "Epoch 2 / 2, Step 140 / 160, Loss: 0.6596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r146it [00:01, 123.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 150 / 160, Loss: 0.9388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "160it [00:01, 126.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 2, Step 160 / 160, Loss: 0.2727\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    nCorrect = 0\n",
        "    nSamples = 0\n",
        "    nClassCorrect = [0 for i in range(4)]\n",
        "    nClassTotal = [0 for i in range(4)]\n",
        "    \n",
        "        \n",
        "    for i,data in tqdm(enumerate(testDataLoader)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        # print(\"l\",labels.shape)\n",
        "        # print(labels)\n",
        "        labels = labels.reshape((-1,)).to(device)\n",
        "        # print(\"l\",labels.shape)\n",
        "        # print(labels)\n",
        "    \n",
        "        outputs = lstm(inputs)\n",
        "        # outputs = torch.squeeze(outputs)\n",
        "        # outputs = outputs.reshape((-1, 1))\n",
        "        # print(outputs.shape)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        nSamples += labels.shape[0]\n",
        "        # nCorrect += (predictions == labels).sum().item()\n",
        "        for i in range(len(predictions)):\n",
        "            if predictions[i] == labels[i]:\n",
        "                nCorrect += 1\n",
        "\n",
        "    \n",
        "    acc = 100.0 * nCorrect / nSamples\n",
        "    print(f'Accuracy on test: {acc:.2f}%')\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjPdbMTRZRjz",
        "outputId": "b28ee5ab-05f6-47bd-e126-ac76f3146121"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23it [00:00, 478.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test: 69.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZezLkMMCjNIf",
        "outputId": "0c74c0fa-7ad6-46c2-c73f-59a5e40d9040"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCI_2NPfjaLW",
        "outputId": "f5c0fa4a-23ec-4ed1-95c1-5cabaa23926d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOh71WFtjgW3",
        "outputId": "29cdcef1-939b-48c6-d354-43cfad33f4de"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5090,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}